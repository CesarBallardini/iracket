{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Factor analysis: the big picture\n",
    "\n",
    "## The model\n",
    "\n",
    "Factor analysis tries to account for the distribution of objects in a high-dimensional feature space by locating each object in a *low-dimensional* space, whose dimensions are traditionally called the *factors*.  Each high-dimensional vectors is a linear function of its low-dimensional one, plus independent noise.  The intuition is that, in the original representation, lots of features are correlated with each other, so there are fewer true directions of variation than there are features.\n",
    "\n",
    "To get a bit more formal, we have to define some things:\n",
    "\n",
    "* $d$ is the number of features in the original representation, and $m$ is the number of factors.  $n$ is the number of objects represented in the data.  For the moment, we are choosing $m$ by guess-work. \n",
    "* $x$ is the $n$-by-$d$ matrix of data.\n",
    "* $z$ is the $n$-by-$m$ matrix of latent representations.\n",
    "* $\\mu$ is the $d$-by-$1$ vector of feature means. \n",
    "* $W$ is a $d$-by-$m$ matrix of weights, which we will assume are independent draws from a zero-mean normal distribution, with some random shared, stipulated (non-random) variance, $\\xi_W^2$. \n",
    "* The $i$th of the $d$ features has a zero-mean noise distribution with a randomly-drawn, feature-specific variance $\\sigma_{i}^2$.  Each of these is drawn from a gamma distribution with shape parameter $\\alpha$ and scale parameter $\\beta$, both stipulated.  We collect the set of $\\sigma_{i}^2$ into a $d$-by-$d$ diagonal matrix $\\Sigma$. \n",
    "\n",
    "\n",
    "$$z_{object,factor} \\sim N(0,1)$$\n",
    "$$\\sigma_{feature} \\sim gamma(\\alpha,\\beta)$$\n",
    "$$x_{object,.} \\sim N(Wz_{object,.} + \\mu,\\Sigma)$$\n",
    "\n",
    "\n",
    "If that's a little too terse, hold on; things will become more clear as we proceed.  For now, it's important to keep in mind that we observe the data $x$, and we infer the latent representations $z$ and the \"factor loadings\" $W$.  \n",
    "\n",
    "## What we want to do with the model\n",
    "\n",
    "Intuitively, factor analysis is doing a good job at compressing high-dimensional representations to low-dimensional ones only if pair-wise similarities between objects are preserved--accurately represented by distances between low-dimensional representations thereof.  One very useful summary of similarities is provided by a dendrogram--a graphical representation of a tree formed by repeatedly linking subtrees (originally $n$ single-object \"trees\") that are \"close\" together.  [mumble mumble...]\n",
    "\n",
    "So, as a first, \"sanity check\" test of our model, we will try to make a tree that looks reasonable, using distances between latent variable representations of objects.\n",
    "\n",
    "\n",
    "##Test data\n",
    "To build and test a factor analysis model, we will use a small, intuitively interpretable data set, collected by psychologist Daniel Osherson (and...): the average rating of many human subjects of the degree to which each of 50 species has each of 85 features.  This data is publicly avaiable at (...).\n",
    "\n",
    "## A few \"requires\"\n",
    "\n",
    "We will need a few special functions that don't come with Gamble...this section is not very interesting, but should be completed, at some point...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(require racket/string\n",
    "         racket/list\n",
    "         racket/vector\n",
    "         \"table_utils.rkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some mysterious parameters\n",
    "\n",
    "I need a story about where these numbers are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define shape 0.5)\n",
    "(define scale 7)\n",
    "(define factor-load-sigma 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Reading in the data\n",
    "\n",
    "\n",
    "The Osherson files are in an odd format, so I have to get the second thing \n",
    "from each row.\n",
    "\n",
    "After loading from these files, the top-level environment will contain\n",
    "\n",
    "* <code>animal-names</code>, a list of 50 animal species.\n",
    "* <code>attribute-names</code>, a list of 85 animal attributes.\n",
    "* <code>animal-data-table</code>, a hash from animal/attribute pairs to numerical values.\n",
    "\n",
    "TODO: Maybe just put all of this info in one R-readable tsv file.  Then we can use standard functions from <code>file_utils.rkt</code>, and hide this one-off junk.  This will require an <code>import-tsv</code> function parallel to the <code>export-tsv</code> one I have now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define animal-names\n",
    "   (with-input-from-file \"animal_classes.txt\"\n",
    "     (lambda ()\n",
    "       (for/list ([line (in-lines)])\n",
    "         (let ([parts (string-split line #px\"\\\\s+\")])\n",
    "           (second parts))))))\n",
    "\n",
    "(define attribute-names\n",
    "   (with-input-from-file \"animal_attributes.txt\"\n",
    "     (lambda ()\n",
    "       (for/list ([line (in-lines)])\n",
    "         (let ([parts (string-split line #px\"\\\\s+\")])\n",
    "           (second parts))))))\n",
    "\n",
    "\n",
    ";; Load the data once, into a hash table\n",
    "(define animal-data-table\n",
    "  (let ([tbl (make-hash)])\n",
    "    (begin\n",
    "      (with-input-from-file \"animal_features.txt\"\n",
    "        (lambda ()\n",
    "          ;; Each row is an animal.\n",
    "          (for ([line (in-lines)]\n",
    "                [animal animal-names])\n",
    "            (let ([attr-vals (string-split line #px\"\\\\s+\")])\n",
    "              ;; Each column is an attribute.\n",
    "              (for ([attribute attribute-names]\n",
    "                    [val attr-vals])\n",
    "                (unless (missing-value? val)\n",
    "                  (hash-set! tbl (cons animal attribute) (string->number val))))))))\n",
    "      tbl)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Setting up a few things\n",
    "\n",
    "Factor analysis assumes zero-centered data, so we will need the attribute means.\n",
    "\n",
    "I index by factor name strings rather than integers, as in a traditional array-based implementation.  The hash table doesn't care."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define mean-value\n",
    "  (make-hash\n",
    "   (map (lambda (name) (cons name (mean-value-of name animal-data-table))) \n",
    "          attribute-names)))\n",
    "  \n",
    "\n",
    "      \n",
    "\n",
    "(define factors (list \"factor1\" \"factor2\" \"factor3\" \"factor4\" \"factor5\")) ; \"factor6\"))\n",
    "                  ;    \"factor7\" \"factor8\" \"factor9\" \"factor10\" \"factor11\" \"factor12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting samples from the posterior\n",
    "\n",
    "What should we sample? What exactly are we interested in? [...]\n",
    "\n",
    "Sampling may move between symmetric modes, so averaging latent vectors themselves\n",
    "may not behave well.  Two options:  \n",
    " 1. Use MAP to pick one set of latent vectors.\n",
    " 2. Compute per-sample inter-animal distances, instead of raw latent vectors.  These \n",
    "    are preserved across symmetries. \n",
    "    \n",
    "#Finally, the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define animals-fa-sampler\n",
    "  (mh-sampler\n",
    "   \n",
    "   ;; We don't know how noisy each observable attribute is.\n",
    "   (defmem (attr-sigma attribute) (gamma shape scale))\n",
    "   \n",
    "   ;; Factors are always assumed independent standard normal.\n",
    "   (defmem (factor-value object factor) (normal 0 1))\n",
    "   \n",
    "   ;; We don't know how variable the factor loads are. But we are guessing.\n",
    "   (defmem (factor-load attribute factor) (normal 0 factor-load-sigma))\n",
    "   \n",
    "   ;; The observable value is the up-projection of the factor vector, plus noise.\n",
    "   (defmem (attribute-value object attribute)\n",
    "     (normal (+ (hash-ref mean-value attribute)\n",
    "                (for/sum ([factor factors])\n",
    "                  (* (factor-load attribute factor)\n",
    "                     (factor-value object factor)))) \n",
    "             (attr-sigma attribute)))\n",
    "   \n",
    "   \n",
    "   (for ([animal animal-names])\n",
    "     (for ([attribute attribute-names])\n",
    "       (let ([val (hash-ref animal-data-table (cons animal attribute) #f)])\n",
    "         (when val\n",
    "           (observe (attribute-value animal attribute) val)))))                \n",
    "                 \n",
    "   ;; Return the latent representations for all animals.\n",
    "   (cross-prod-hash animal-names factors factor-value)\n",
    "   #:transition (slice)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Musings on the results \n",
    "\n",
    "It took hours of sampling (a 12K sample burn in) to get nice samples.  \n",
    "\n",
    "    (define smpls (generate-samples animals-fa-sampler 100 #:burn 1000 #:thin 50))\n",
    "    (define mean-dists (mean-distance-table smpls factors animal-names))\n",
    "    \n",
    "    \n",
    "Here's the clustering produced:\n",
    "\n",
    "\n",
    "<br>\n",
    "<center><img src=\"animals_fa5.jpg\" width=700px></center>\n",
    "<br>\n",
    "\n",
    "\n",
    "Two lessons:\n",
    "\n",
    "1. We should really be using gradients when we can--HMC.\n",
    "\n",
    "2. We should allow ad hoc initialization.  In this case, using fast ML or MAP from \n",
    "   some standard stats package.\n",
    "\n",
    "Now that I got the plain vanilla version to work, it would be nice to try one with a sparse\n",
    "factor load matrix--more interpretable (ICA, I think)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define smpls (generate-samples animals-fa-sampler 10 #:burn 10 #:thin 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "(define mean-dists (mean-distance-table smpls factors animal-names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Racket",
   "language": "racket",
   "name": "racket"
  },
  "language_info": {
   "codemirror_mode": "scheme",
   "file_extension": ".rkt",
   "mimetype": "text/x-gamble",
   "name": "Gamble",
   "pygments_mode": "racket",
   "version": "6.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
