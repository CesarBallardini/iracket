{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Bayesian concept learning\n",
    "\n",
    "Suppose we have a population of objects, each represented by a vector of features.  Similar objects have similar feature vectors.  We get only a few positive examples of a concept--say \"dog\"--that we want generalize correctly.  Which of the other objects are dogs?\n",
    "\n",
    "The model below is a fuzzy variant of \"Bayesian concept learning\", as proposed by Josh Tenenbaum in his dissertation (ref).  Rather than assuming the objects are either in or not in the extension of the to-be-learned concept, we assume that each has some degree of membership.  The probability that an object is drawn as an example is proportional to its degree of \"in-ness\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Some data to play with\n",
    "\n",
    "We populate a hash table whose keys are object name strings and whose values are eleven-dimensional vectors of real numbers.  Vectors for 96 objects have been constructed from about 2000 rdf (subject-verb-object) triples describing them, by means that would take us too far afield to discuss.  Suffice it to say that an iterative algoritm ensures that objects that occur in similar contexts have similar vectors.  \n",
    "\n",
    "TODO: fix the csv utils so I don't have to do all the whitespace trimming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(require gamble\n",
    "         gamble/util/csv\n",
    "         racket/string\n",
    "         racket/vector\n",
    "         \"c3_helpers.rkt\"\n",
    "         racket/list)\n",
    "\n",
    "(define object-codes \n",
    "  (make-hash\n",
    "      (map \n",
    "       (lambda (row)\n",
    "         (cons (string-trim (vector-ref row 0))\n",
    "               (map (lambda (n) \n",
    "                      (string->number \n",
    "                       (string-trim n)))\n",
    "                   (vector->list (vector-drop row 1)))))\n",
    "       (read-csv-file \"toy_vectors.csv\"))))\n",
    "\n",
    "(define n-features 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Having a look at the object vectors\n",
    "\n",
    "If we look at the cosine similarity of object vectors, we can see that our intuitions of relative similarity are mostly respected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ";; Cosine.\n",
    "(define (similarity obj1 obj2)\n",
    "  (let ([v1 (hash-ref object-codes obj1)]\n",
    "        [v2 (hash-ref object-codes obj2)])\n",
    "    (let ([l1 (sqrt (apply + (map * v1 v1)))]\n",
    "          [l2 (sqrt (apply + (map * v2 v2)))])\n",
    "     (/ (apply + (map * v1 v2)) (* l1 l2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        dog1 (individual) / dog2 (individual):\t\t0.9962\n",
      "\n",
      "        dog1 (individual) / dog (class in):\t\t0.8803\n",
      "\n",
      "        dog1 (individual) / subPropertyOf (2n-ord rel):\t0.788\n",
      "\n",
      "        theft (class) /  transfer (super-class):\t0.9996"
     ]
    }
   ],
   "source": [
    "(printf \"\n",
    "        dog1 (individual) / dog2 (individual):\\t\\t~a\\n\n",
    "        dog1 (individual) / dog (class in):\\t\\t~a\\n\n",
    "        dog1 (individual) / subPropertyOf (2n-ord rel):\\t~a\\n\n",
    "        theft (class) /  transfer (super-class):\\t~a\"\n",
    "        (/ (round (* 10000 (similarity \"toy_dog1\" \"toy_dog2\"))) 10000)\n",
    "        (/ (round (* 10000 (similarity \"toy_dog1\" \"toy_Dog\"))) 10000)\n",
    "        (/ (round (* 10000 (similarity \"toy_dog1\" \"rdfs_subPropertyOf\"))) 10000)\n",
    "        (/ (round (* 10000 (similarity \"toy_Theft\" \"toy_Transfer\"))) 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The model\n",
    "\n",
    "We see several examples, which are assumed to be drawn thusly: \n",
    "\n",
    "1. First each element of the concept mean vector $\\mu^c$ is drawn from an independent Gaussian.\n",
    "\n",
    "2. For each dimension, a concept-specific precision (a length-scale or importance weight) $\\tau^c_j$, is drawn from a mixture of a spike at zero (feature is irrelevant) and a vague gamma distribution.\n",
    "\n",
    "3. The item's degree of in-ness is exponentially decreasing in its weighted city-block distance from the concept mean:\n",
    "\n",
    "$$g^c_i = e^{-\\sum_j \\tau^c_j |x_{ij}-\\mu^c_j|}$$\n",
    "\n",
    "3. The vector of \"in-nesses\" is normalized (automatically, in construction) to produce a discrete distribution over objects, from which examples are then drawn.\n",
    "\n",
    "Inference yields in-nesses for several objects, given weights sampled from the posterior, which will favor concentrating in-ness on the examples, and (within the strong smoothness constraint imposed by the model form) avoiding weight on non-examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(define bcl-sampler\n",
    "  (mh-sampler\n",
    "   \n",
    "   ;;;;;;;  Generative model ;;;;;;;;;\n",
    "   \n",
    "   (deflazy p-relevant (beta 2 2)) \n",
    "   \n",
    "   ;; The mean and precision vectors that define the concept.\n",
    "   (defmem (precision concept feature) (if (flip p-relevant) 0.000000001 (gamma 0.6 12.0)))   \n",
    "   (defmem (mean concept feature) (normal 0 8))\n",
    "   \n",
    "   ;; In-ness decreases exponentially with city-block distance from concept means,\n",
    "   ;; with block directions scaled by precisions.\n",
    "   (define (in-ness object concept)\n",
    "      (let ([obj-ftrs (hash-ref object-codes object)])\n",
    "        (+ 0.0000000000001\n",
    "          (exp \n",
    "           (for/sum ([i (length obj-ftrs)])\n",
    "                (let ([ftr-diff (- (mean concept i) (list-ref obj-ftrs i))])\n",
    "                  (* -1 (precision concept i) (abs ftr-diff))))))))\n",
    "                    ;(* -1 (precision concept i) (* ftr-diff ftr-diff))))))))\n",
    "   \n",
    "   \n",
    "   ;; The set of in-ness-es that defines the concept's discrete distribution.\n",
    "   (defmem (weighted-objects concept)\n",
    "      (map \n",
    "         (lambda (obj)\n",
    "            (cons obj (in-ness obj concept)))\n",
    "         (hash-keys object-codes)))\n",
    "\n",
    "   ;; Drawing examples from that distribution.\n",
    "   (defmem (examples concept k) (discrete (weighted-objects concept)))\n",
    "   \n",
    "   \n",
    "   ;;;;;;;;; Observations ;;;;;;;;;;;\n",
    "   \n",
    "   (observe (examples \"chien\" 1) \"toy_dog1\")\n",
    "   (observe (examples \"chien\" 2) \"toy_dog2\")\n",
    "   (observe (examples \"chien\" 3) \"toy_dog11\")\n",
    "   (observe (examples \"chien\" 4) \"toy_dog12\")\n",
    "   (observe (examples \"chien\" 5) \"toy_dog4\")\n",
    "   (observe (examples \"chien\" 6) \"toy_dog14\")\n",
    "   \n",
    "   (observe (examples \"personne\" 1) \"toy_person1\")\n",
    "   (observe (examples \"personne\" 2) \"toy_person2\")\n",
    "   (observe (examples \"personne\" 3) \"toy_person11\")\n",
    "   (observe (examples \"personne\" 4) \"toy_person12\")\n",
    "   (observe (examples \"personne\" 5) \"toy_person4\")\n",
    "   (observe (examples \"personne\" 6) \"toy_person14\")\n",
    "   (observe (examples \"personne\" 7) \"toy_person23\")\n",
    "   (observe (examples \"personne\" 8) \"toy_person33\")\n",
    "   \n",
    "   (observe (examples \"transfert\" 1) \"toy_giveEvt1\")\n",
    "   (observe (examples \"transfert\" 2) \"toy_theft1\")\n",
    "   \n",
    "   \n",
    "   ;;;;;;;;; Query ;;;;;;;;;;;;;;;\n",
    "   \n",
    "   (vector \n",
    "    (in-ness \"toy_dog4\" \"chien\")\n",
    "    (in-ness \"toy_dog3\" \"chien\")\n",
    "    (in-ness \"toy_dog13\" \"chien\")\n",
    "    (in-ness \"toy_person3\" \"chien\")\n",
    "    (in-ness \"toy_person13\" \"chien\")\n",
    "    (in-ness \"toy_theft1\" \"chien\")\n",
    "    (in-ness \"toy_giveEvt2\" \"chien\")\n",
    "    (in-ness \"rdfs_subPropertyOf\" \"chien\")\n",
    "    (in-ness \"toy_dog4\" \"transfert\")\n",
    "    (in-ness \"toy_dog3\" \"transfert\")\n",
    "    (in-ness \"toy_dog13\" \"transfert\")\n",
    "    (in-ness \"toy_person3\" \"transfert\")\n",
    "    (in-ness \"toy_person13\" \"transfert\")\n",
    "    (in-ness \"toy_theft1\" \"transfert\")\n",
    "    (in-ness \"toy_giveEvt2\" \"transfert\")\n",
    "    (in-ness \"rdfs_subPropertyOf\" \"transfert\")\n",
    "    (in-ness \"toy_dog4\" \"personne\")\n",
    "    (in-ness \"toy_dog3\" \"personne\")\n",
    "    (in-ness \"toy_dog13\" \"personne\")\n",
    "    (in-ness \"toy_person3\" \"personne\")\n",
    "    (in-ness \"toy_person13\" \"personne\")\n",
    "    (in-ness \"toy_theft1\" \"personne\")\n",
    "    (in-ness \"toy_giveEvt2\" \"personne\")\n",
    "    (in-ness \"rdfs_subPropertyOf\" \"personne\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(define smpls (sampler->mean bcl-sampler 50 #:burn 10000 #:thin 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Results\n",
    "\n",
    "## Dogs (\"chien\")\n",
    "\n",
    "As we expect (or hope), generalization is strongest to dogs (the left-most three bars, only the first of which is an example), and next-strongest to people (the next two bars to the right).  Generalization is very low to a theft event and a gift event (the next two), and non-existent to the abstract property \"subPropertyOf\".\n",
    "\n",
    "This is significant, if simple, learning from just a few examples, with no negative examples at all, based on a model no more complex than logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/x-c3-data": "{\"data\":{\"type\":\"bar\",\"xs\":{\"ys1\":\"xs1\"},\"columns\":[[\"xs1\",\"dog4\",\"dog3\",\"dog13\",\"person3\",\"person13\",\"theft1\",\"gift2\",\"subPropertyOf\"],[\"ys1\",0.23306451574231118,0.23268185349666237,0.23276698178814326,0.032757574823156096,0.039245501256883204,0.0033472494241386375,0.0030088837413401836,0.0006507559608831496]]},\"axis\":{\"x\":{\"type\":\"category\",\"label\":\"object\",\"tick\":{\"rotate\":90}},\"y\":{\"label\":\"mean in-ness\"}}}",
      "text/plain": [
       "(c3-data . #hasheq((data . #hasheq((type . bar) (xs . #hasheq((ys1 . xs1))) (columns . ((xs1 dog4 dog3 dog13 person3 person13 theft1 gift2 subPropertyOf) (ys1 0.23306451574231118 0.23268185349666237 0.23276698178814326 0.032757574823156096 0.039245501256883204 0.0033472494241386375 0.0030088837413401836 0.0006507559608831496))))) (axis . #hasheq((x . #hasheq((type . category) (label . object) (tick . #hasheq((rotate . 90))))) (y . #hasheq((label . mean in-ness)))))))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bar-c3-categorical \n",
    " (list 1 2 3 4 5 6 7 8)\n",
    " (take (vector->list smpls) 8)\n",
    " (list \"dog4\" \"dog3\" \"dog13\" \"person3\" \"person13\" \"theft1\" \"gift2\" \"subPropertyOf\")\n",
    " #:xlabel \"object\"\n",
    " #:ylabel \"mean in-ness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Transfer events (\"transfert\") \n",
    "\n",
    "Here we can give only two examples, because there are only three in the data set, and we want one to test generalization on (the second right-most bar).  We don't get the clear separation we got with dogs, but the two transfer events are the most \"in\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/x-c3-data": "{\"data\":{\"type\":\"bar\",\"xs\":{\"ys1\":\"xs1\"},\"columns\":[[\"xs1\",\"dog4\",\"dog3\",\"dog13\",\"person3\",\"person13\",\"theft1\",\"gift2\",\"subPropertyOf\"],[\"ys1\",0.15757171525798097,0.15756628444364007,0.15756713526614774,0.15800038556396417,0.15801798151283028,0.15964610643379398,0.1596421526379694,0.15537696410151314]]},\"axis\":{\"x\":{\"type\":\"category\",\"label\":\"object\",\"tick\":{\"rotate\":90}},\"y\":{\"label\":\"mean in-ness\"}}}",
      "text/plain": [
       "(c3-data . #hasheq((data . #hasheq((type . bar) (xs . #hasheq((ys1 . xs1))) (columns . ((xs1 dog4 dog3 dog13 person3 person13 theft1 gift2 subPropertyOf) (ys1 0.15757171525798097 0.15756628444364007 0.15756713526614774 0.15800038556396417 0.15801798151283028 0.15964610643379398 0.1596421526379694 0.15537696410151314))))) (axis . #hasheq((x . #hasheq((type . category) (label . object) (tick . #hasheq((rotate . 90))))) (y . #hasheq((label . mean in-ness)))))))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bar-c3-categorical \n",
    " (list 1 2 3 4 5 6 7 8)\n",
    " (take (drop (vector->list smpls) 8) 8)\n",
    " (list \"dog4\" \"dog3\" \"dog13\" \"person3\" \"person13\" \"theft1\" \"gift2\" \"subPropertyOf\")\n",
    " #:xlabel \"object\"\n",
    " #:ylabel \"mean in-ness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##People (\"personne\")\n",
    "\n",
    "Not quite as convincing as dogs, but a pretty clear lead for test people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/x-c3-data": "{\"data\":{\"type\":\"bar\",\"xs\":{\"ys1\":\"xs1\"},\"columns\":[[\"xs1\",\"dog4\",\"dog3\",\"dog13\",\"person3\",\"person13\",\"theft1\",\"gift2\",\"subPropertyOf\"],[\"ys1\",0.09372239953674008,0.0937380702327446,0.09373656470551471,0.07858638390565596,0.07977350928868006,0.05756917045909583,0.05633289552346623,0.04272118117197834]]},\"axis\":{\"x\":{\"type\":\"category\",\"label\":\"object\",\"tick\":{\"rotate\":90}},\"y\":{\"label\":\"mean in-ness\"}}}",
      "text/plain": [
       "(c3-data . #hasheq((data . #hasheq((type . bar) (xs . #hasheq((ys1 . xs1))) (columns . ((xs1 dog4 dog3 dog13 person3 person13 theft1 gift2 subPropertyOf) (ys1 0.09372239953674008 0.0937380702327446 0.09373656470551471 0.07858638390565596 0.07977350928868006 0.05756917045909583 0.05633289552346623 0.04272118117197834))))) (axis . #hasheq((x . #hasheq((type . category) (label . object) (tick . #hasheq((rotate . 90))))) (y . #hasheq((label . mean in-ness)))))))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bar-c3-categorical \n",
    " (list 1 2 3 4 5 6 7 8)\n",
    " (drop (vector->list smpls) 16)\n",
    " (list \"dog4\" \"dog3\" \"dog13\" \"person3\" \"person13\" \"theft1\" \"gift2\" \"subPropertyOf\")\n",
    " #:xlabel \"object\"\n",
    " #:ylabel \"mean in-ness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Racket",
   "language": "racket",
   "name": "racket"
  },
  "language_info": {
   "codemirror_mode": "scheme",
   "file_extension": ".rkt",
   "mimetype": "text/x-racket",
   "name": "Racket",
   "pygments_lexer": "racket",
   "version": "6.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
